{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b323f441-93b8-4b61-b874-22d099a4df07",
   "metadata": {},
   "source": [
    "# OpenAI Whisper LoRA 模型评估和推理\n",
    "\n",
    "本教程将加载 LoRA 微调后的 Whisper 模型进行模型评估（基于 WER 指标），并将数据处理和模型准备流程也整合进来。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5a62f2-1079-4f06-8afc-9135db361d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:38:18.073705Z",
     "iopub.status.busy": "2024-07-01T08:38:18.073190Z",
     "iopub.status.idle": "2024-07-01T08:38:18.090727Z",
     "shell.execute_reply": "2024-07-01T08:38:18.087390Z",
     "shell.execute_reply.started": "2024-07-01T08:38:18.073633Z"
    }
   },
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "model_name_or_path = \"openai/whisper-large-v2\"\n",
    "model_dir = \"models/whisper-large-v2-asr-int8\"\n",
    "\n",
    "language = \"Chinese (China)\"\n",
    "language_abbr = \"zh-CN\"\n",
    "task = \"transcribe\"\n",
    "dataset_name = \"mozilla-foundation/common_voice_11_0\"\n",
    "\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c638814-d20b-4af9-b9c4-09f76ba1b631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:38:18.094962Z",
     "iopub.status.busy": "2024-07-01T08:38:18.094185Z",
     "iopub.status.idle": "2024-07-01T08:38:48.665883Z",
     "shell.execute_reply": "2024-07-01T08:38:48.665084Z",
     "shell.execute_reply.started": "2024-07-01T08:38:18.094910Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/zlhu/miniconda3/envs/peft/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WhisperForConditionalGeneration(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(80, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperSdpaAttention(\n",
       "            (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear8bitLt(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear8bitLt(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51865, 1280, padding_idx=50257)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperDecoderLayer(\n",
       "          (self_attn): WhisperSdpaAttention(\n",
       "            (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperSdpaAttention(\n",
       "            (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear8bitLt(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear8bitLt(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Linear(in_features=1280, out_features=51865, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入模型\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoTokenizer, AutoProcessor\n",
    "from peft import PeftConfig, PeftModel\n",
    "\n",
    "peft_config = PeftConfig.from_pretrained(model_dir)\n",
    "\n",
    "base_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",
    ")\n",
    "base_model.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a1d9e4-e243-46e4-bff5-8d51ab302d21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:38:48.667061Z",
     "iopub.status.busy": "2024-07-01T08:38:48.666801Z",
     "iopub.status.idle": "2024-07-01T08:38:48.917297Z",
     "shell.execute_reply": "2024-07-01T08:38:48.916699Z",
     "shell.execute_reply.started": "2024-07-01T08:38:48.667043Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): WhisperForConditionalGeneration(\n",
       "      (model): WhisperModel(\n",
       "        (encoder): WhisperEncoder(\n",
       "          (conv1): Conv1d(80, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "          (embed_positions): Embedding(1500, 1280)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x WhisperEncoderLayer(\n",
       "              (self_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): lora.Linear8bitLt(\n",
       "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear8bitLt(\n",
       "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear8bitLt(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear8bitLt(in_features=5120, out_features=1280, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): WhisperDecoder(\n",
       "          (embed_tokens): Embedding(51865, 1280, padding_idx=50257)\n",
       "          (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x WhisperDecoderLayer(\n",
       "              (self_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): lora.Linear8bitLt(\n",
       "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear8bitLt(\n",
       "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (activation_fn): GELUActivation()\n",
       "              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (encoder_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): lora.Linear8bitLt(\n",
       "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear8bitLt(\n",
       "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear8bitLt(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear8bitLt(in_features=5120, out_features=1280, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Linear(in_features=1280, out_features=51865, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model = PeftModel.from_pretrained(base_model, model_dir)\n",
    "peft_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb02d5f-07f5-4ef1-87cb-0c81925bf586",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:38:48.918238Z",
     "iopub.status.busy": "2024-07-01T08:38:48.918054Z",
     "iopub.status.idle": "2024-07-01T08:40:00.371399Z",
     "shell.execute_reply": "2024-07-01T08:40:00.370846Z",
     "shell.execute_reply.started": "2024-07-01T08:38:48.918221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
    "processor = AutoProcessor.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
    "feature_extractor = processor.feature_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec285096-52a5-4e7a-9520-451c1b17c349",
   "metadata": {},
   "source": [
    "## 评估数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9646f874-182c-4a6b-b000-b35f90fc893e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:40:00.372384Z",
     "iopub.status.busy": "2024-07-01T08:40:00.372143Z",
     "iopub.status.idle": "2024-07-01T08:41:42.073020Z",
     "shell.execute_reply": "2024-07-01T08:41:42.071816Z",
     "shell.execute_reply.started": "2024-07-01T08:40:00.372365Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /data/zlhu/.cache/huggingface/modules/datasets_modules/datasets/mozilla-foundation--common_voice_11_0/c53480f5cff967cae51f6bec35b814267cfca418b908540c19985156c4523fb5 (last modified on Sun Jun 23 23:00:19 2024) since it couldn't be found locally at mozilla-foundation/common_voice_11_0, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Audio\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "common_voice[\"test\"] = load_dataset(dataset_name, language_abbr, split=\"test\", trust_remote_code=True)\n",
    "common_voice = common_voice.remove_columns(\n",
    "    [\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"]\n",
    ")\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0f0d3f-71d5-4cae-8230-70b1fb4548d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:41:42.075967Z",
     "iopub.status.busy": "2024-07-01T08:41:42.075492Z",
     "iopub.status.idle": "2024-07-01T08:41:42.080624Z",
     "shell.execute_reply": "2024-07-01T08:41:42.079927Z",
     "shell.execute_reply.started": "2024-07-01T08:41:42.075942Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be3d5a3c-d498-4250-a590-ccd51e9b03f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:41:42.081743Z",
     "iopub.status.busy": "2024-07-01T08:41:42.081411Z",
     "iopub.status.idle": "2024-07-01T08:41:42.095282Z",
     "shell.execute_reply": "2024-07-01T08:41:42.094367Z",
     "shell.execute_reply.started": "2024-07-01T08:41:42.081722Z"
    }
   },
   "outputs": [],
   "source": [
    "small_common_voice = DatasetDict()\n",
    "\n",
    "small_common_voice[\"test\"] = common_voice[\"test\"].shuffle(seed=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c4e47ac-2001-47c0-a53a-9490c94bc784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:41:42.096848Z",
     "iopub.status.busy": "2024-07-01T08:41:42.096462Z",
     "iopub.status.idle": "2024-07-01T09:04:45.991620Z",
     "shell.execute_reply": "2024-07-01T09:04:45.990304Z",
     "shell.execute_reply.started": "2024-07-01T08:41:42.096822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6c0c63ac7046f7af4f42670bb0fc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10581 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_common_voice = small_common_voice.map(prepare_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3875e35-9c9f-47d6-be11-ee553723179d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T09:04:45.994242Z",
     "iopub.status.busy": "2024-07-01T09:04:45.993530Z",
     "iopub.status.idle": "2024-07-01T09:04:46.003720Z",
     "shell.execute_reply": "2024-07-01T09:04:46.002178Z",
     "shell.execute_reply.started": "2024-07-01T09:04:45.994186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'sentence', 'input_features', 'labels'],\n",
       "        num_rows: 10581\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_common_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2aa0d9e-8ca7-47ed-8856-cebce1d93c65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T09:04:46.007005Z",
     "iopub.status.busy": "2024-07-01T09:04:46.006070Z",
     "iopub.status.idle": "2024-07-01T09:04:46.021443Z",
     "shell.execute_reply": "2024-07-01T09:04:46.020002Z",
     "shell.execute_reply.started": "2024-07-01T09:04:46.006926Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "# 定义一个针对语音到文本任务的数据整理器类\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any  # 处理器结合了特征提取器和分词器\n",
    "\n",
    "    # 整理器函数，将特征列表处理成一个批次\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # 从特征列表中提取输入特征，并填充以使它们具有相同的形状\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # 从特征列表中提取标签特征（文本令牌），并进行填充\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # 使用-100替换标签中的填充区域，-100通常用于在损失计算中忽略填充令牌\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # 如果批次中的所有序列都以句子开始令牌开头，则移除它\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        # 将处理过的标签添加到批次中\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch  # 返回最终的批次，准备好进行训练或评估\n",
    "\n",
    "# 用给定的处理器实例化数据整理器\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eeb613-1dfb-45f0-828d-36150ed5b335",
   "metadata": {},
   "source": [
    "## 评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e774b45-69a9-4f95-938d-e3284ff6060f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T09:04:46.023736Z",
     "iopub.status.busy": "2024-07-01T09:04:46.023208Z",
     "iopub.status.idle": "2024-07-01T09:04:46.426078Z",
     "shell.execute_reply": "2024-07-01T09:04:46.424629Z",
     "shell.execute_reply.started": "2024-07-01T09:04:46.023688Z"
    }
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# 词错误率（WER）是评估ASR模型常用的指标。从 Evaluate 加载 WER 指标\n",
    "metric = evaluate.load(\"../evaluate/metrics/wer/wer.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e5c0c9d-5ccd-4770-9cfc-78e51c956baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T09:04:46.429058Z",
     "iopub.status.busy": "2024-07-01T09:04:46.428040Z",
     "iopub.status.idle": "2024-07-01T09:04:46.436845Z",
     "shell.execute_reply": "2024-07-01T09:04:46.435335Z",
     "shell.execute_reply.started": "2024-07-01T09:04:46.428996Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "eval_dataloader = DataLoader(tokenized_common_voice[\"test\"], batch_size=batch_size, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1371372-b803-4cb0-96a2-110df3d52541",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T09:04:46.439524Z",
     "iopub.status.busy": "2024-07-01T09:04:46.438695Z",
     "iopub.status.idle": "2024-07-02T00:12:39.576748Z",
     "shell.execute_reply": "2024-07-02T00:12:39.576179Z",
     "shell.execute_reply.started": "2024-07-01T09:04:46.439472Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/662 [00:00<?, ?it/s]/data/zlhu/miniconda3/envs/peft/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "100%|██████████| 662/662 [15:07:53<00:00, 82.29s/it]   \n"
     ]
    }
   ],
   "source": [
    "# 遍历评估数据加载器中的所有批次\n",
    "for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "    # 使用自动混合精度来加速计算，并减少显存使用\n",
    "    with torch.cuda.amp.autocast():\n",
    "        # 不计算梯度，以节省计算资源，仅用于推理和评估\n",
    "        with torch.no_grad():\n",
    "            # 生成预测的标记(tokens)，这里使用模型的generate函数进行文本生成\n",
    "            generated_tokens = (\n",
    "                peft_model.generate(\n",
    "                    input_features=batch[\"input_features\"].to(\"cuda\"),  # 将输入特征移动到GPU上\n",
    "                    decoder_input_ids=batch[\"labels\"][:, :4].to(\"cuda\"),  # 提供解码器的初始输入\n",
    "                    max_new_tokens=255,  # 设置生成的最大新标记数量\n",
    "                )\n",
    "                .cpu()  # 将生成的标记移回CPU\n",
    "                .numpy()  # 转换为NumPy数组以便进一步处理\n",
    "            )\n",
    "            # 获取批次中的标签，并将其移回CPU\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "            # 将标签中的-100替换为填充标记的ID，-100通常用于忽略计算损失的标记\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            # 使用分词器解码生成的标记和标签，以获得可读的文本\n",
    "            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "            # 将预测和参考添加到评估指标中，用于后续的性能评估\n",
    "            metric.add_batch(\n",
    "                predictions=decoded_preds,\n",
    "                references=decoded_labels,\n",
    "            )\n",
    "    # 删除不再需要的变量以释放内存\n",
    "    del generated_tokens, labels, batch\n",
    "    # 手动触发垃圾收集，进一步清理内存\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41525e3b-3fe5-45cc-9e5c-32033960f424",
   "metadata": {},
   "source": [
    "### 使用全量数据微调后，对比 WER 指标降低了多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2276bf1-1ab3-453c-9c7a-93486b829332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T00:12:39.578009Z",
     "iopub.status.busy": "2024-07-02T00:12:39.577742Z",
     "iopub.status.idle": "2024-07-02T00:12:39.863799Z",
     "shell.execute_reply": "2024-07-02T00:12:39.863166Z",
     "shell.execute_reply.started": "2024-07-02T00:12:39.577982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer=55.90625590625591%\n"
     ]
    }
   ],
   "source": [
    "# 计算词错误率（WER）指标，并将结果转换为百分比形式\n",
    "wer = 100 * metric.compute()\n",
    "\n",
    "# 打印词错误率，f\"{wer=}\"是一种格式化字符串的简洁写法，它会展示变量名和值\n",
    "print(f\"{wer=}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b724df9a-0175-4002-a395-e59db018a4ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T03:16:37.900113Z",
     "iopub.status.busy": "2024-07-02T03:16:37.899478Z",
     "iopub.status.idle": "2024-07-02T03:16:37.909377Z",
     "shell.execute_reply": "2024-07-02T03:16:37.907573Z",
     "shell.execute_reply.started": "2024-07-02T03:16:37.900060Z"
    }
   },
   "source": [
    "       使用全量微调前     后 \n",
    "错误率    70%           55.9%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peft",
   "language": "python",
   "name": "peft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0ba12dc1696645d09666b9ddc77f22af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1ae77b380ae5443b8a095e9b0c8386dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ebb7ce74dd524749b39e6cea424f6e7f",
       "style": "IPY_MODEL_51244f88c43948b78be881655a0c4923",
       "value": "Map: 100%"
      }
     },
     "4f6c0c63ac7046f7af4f42670bb0fc2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1ae77b380ae5443b8a095e9b0c8386dc",
        "IPY_MODEL_833520eeb8d643f1a3357e34dc860a7e",
        "IPY_MODEL_6f05cc15f3fb475e8769ceffb93ec7dd"
       ],
       "layout": "IPY_MODEL_0ba12dc1696645d09666b9ddc77f22af"
      }
     },
     "51244f88c43948b78be881655a0c4923": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "66102f95a7e3464a9309c8f42077bb07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6f05cc15f3fb475e8769ceffb93ec7dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_efc6e9b332ad4be793115f0c4d599708",
       "style": "IPY_MODEL_caf54ee8628e4ad2b854fa5092c5befa",
       "value": " 10581/10581 [23:03&lt;00:00,  2.62s/ examples]"
      }
     },
     "833520eeb8d643f1a3357e34dc860a7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_66102f95a7e3464a9309c8f42077bb07",
       "max": 10581,
       "style": "IPY_MODEL_e549688de41f41b1a8f2a03665c3fb87",
       "value": 10581
      }
     },
     "caf54ee8628e4ad2b854fa5092c5befa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e549688de41f41b1a8f2a03665c3fb87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ebb7ce74dd524749b39e6cea424f6e7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "efc6e9b332ad4be793115f0c4d599708": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
